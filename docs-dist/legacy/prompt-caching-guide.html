<!DOCTYPE html>
<html>
<head>
    <title>Guide d'Impl√©mentation du Prompt Caching OpenAI</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css">
    <style>
        body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', sans-serif; }
        .markdown { max-width: 5xl; margin: 0 auto; padding: 2rem; }
        h1 { font-size: 2.5rem; font-weight: 700; margin-bottom: 1.5rem; color: #1f2937; }
        h2 { font-size: 2rem; font-weight: 600; margin-top: 2.5rem; margin-bottom: 1rem; color: #374151; }
        h3 { font-size: 1.5rem; font-weight: 500; margin-top: 2rem; margin-bottom: 0.75rem; color: #4b5563; }
        h4 { font-size: 1.25rem; font-weight: 500; margin-top: 1.5rem; margin-bottom: 0.5rem; color: #6b7280; }
        p { margin-bottom: 1rem; line-height: 1.7; color: #374151; }
        pre { background: #f3f4f6; padding: 1rem; border-radius: 0.5rem; overflow-x: auto; margin-bottom: 1rem; }
        code:not(pre code) { background: #e5e7eb; padding: 0.2rem 0.4rem; border-radius: 0.25rem; font-size: 0.875rem; }
        ul, ol { margin-bottom: 1rem; padding-left: 2rem; }
        li { margin-bottom: 0.5rem; line-height: 1.6; }
        table { width: 100%; border-collapse: collapse; margin-bottom: 1rem; }
        th, td { border: 1px solid #d1d5db; padding: 0.75rem; text-align: left; }
        th { background: #f9fafb; font-weight: 600; }
    </style>
</head>
<body class="bg-gray-50 text-gray-900">
    <div class="markdown">
        <div class="mb-8">
            <a href="../index.html" class="text-blue-600 hover:text-blue-800">
                ‚Üê Retour √† la documentation
            </a>
        </div>
        <div class="prose prose-lg max-w-none">
<h1>Guide d'Impl√©mentation du Prompt Caching OpenAI</h1>

<h2>üìã Vue d'ensemble</h2>

<p>Ce guide d√©taille l'impl√©mentation du prompt caching natif d'OpenAI dans le projet Intelligent Transcription. Le prompt caching permet de r√©duire les co√ªts jusqu'√† 50% et la latence jusqu'√† 80% pour les prompts de plus de 1024 tokens.</p>

<h2>üéØ Objectifs</h2>

<p>- **R√©duction des co√ªts** : √âconomiser ~50% sur les tokens de prompt r√©currents</p>
<p>- **Am√©lioration des performances** : R√©duire la latence de 40-80%</p>
<p>- **Optimisation automatique** : Aucune modification du code applicatif n√©cessaire</p>
<p>- **Suivi des m√©triques** : Dashboard int√©gr√© pour monitorer les performances</p>

<h2>üöÄ Guide de Migration</h2>

<h3>1. Configuration de l'Organization ID</h3>

<p>L'Organization ID a √©t√© configur√© dans le projet :</p>
<p>```</p>
<p>Organization ID: org-HzNhomFpeY5ewhrUNlmpTehv</p>
<p>```</p>

<p>**V√©rification** :</p>
<p>```bash</p>
<h1>V√©rifier la configuration</h1>
<p>grep OPENAI_ORG_ID .env</p>
<p>grep OPENAI_ORG_ID config.php</p>
<p>```</p>

<h3>2. Migration de la Base de Donn√©es</h3>

<p>Ex√©cutez le script de migration pour cr√©er les tables n√©cessaires :</p>

<p>```bash</p>
<p>php migrate_openai_cache.php</p>
<p>```</p>

<p>Ce script cr√©e :</p>
<p>- Table `openai_cache_metrics` pour stocker les m√©triques</p>
<p>- Table `openai_cache_daily_stats` pour les statistiques agr√©g√©es</p>
<p>- Vues `openai_cache_hourly_stats` et `openai_cache_model_stats`</p>
<p>- Triggers pour l'agr√©gation automatique</p>

<h3>3. Validation de l'Installation</h3>

<p>Ex√©cutez le script de test pour valider l'impl√©mentation :</p>

<p>```bash</p>
<p>php test_prompt_caching.php</p>
<p>```</p>

<p>Ce script v√©rifie :</p>
<p>- ‚úÖ PromptCacheManager g√©n√®re des prompts >1024 tokens</p>
<p>- ‚úÖ PromptUtils utilise les prompts optimis√©s</p>
<p>- ‚úÖ Les m√©triques de cache sont captur√©es</p>
<p>- ‚úÖ CacheService enregistre les statistiques</p>

<h3>4. Monitoring dans le Dashboard</h3>

<p>Acc√©dez au dashboard analytics pour voir les m√©triques :</p>
<p>```</p>
<p>http://votre-site.com/analytics.php</p>
<p>```</p>

<h2>üìä M√©triques Disponibles</h2>

<h3>M√©triques en Temps R√©el</h3>
<p>- **Cache Hit Rate** : Pourcentage de tokens servis depuis le cache</p>
<p>- **Tokens √âconomis√©s** : Nombre total de tokens cach√©s</p>
<p>- **√âconomies R√©alis√©es** : Estimation en USD des √©conomies</p>
<p>- **Requ√™tes √âligibles** : Nombre de requ√™tes avec prompts ‚â•1024 tokens</p>

<h3>Statistiques Agr√©g√©es</h3>
<p>- Statistiques horaires via `openai_cache_hourly_stats`</p>
<p>- Statistiques quotidiennes via `openai_cache_daily_stats`</p>
<p>- Statistiques par mod√®le via `openai_cache_model_stats`</p>

<h2>üõ†Ô∏è Architecture Technique</h2>

<h3>Composants Principaux</h3>

<p>1. **PromptCacheManager.php**</p>
<p>   - G√®re les prompts statiques optimis√©s (>1024 tokens)</p>
<p>   - Assure le padding automatique si n√©cessaire</p>
<p>   - Fournit des m√©thodes pour extraire les m√©triques</p>

<p>2. **openai_cache_utils.py**</p>
<p>   - Extrait les m√©triques de cache des r√©ponses API</p>
<p>   - Calcule les √©conomies estim√©es</p>
<p>   - Formate les rapports de performance</p>

<p>3. **CacheService.php**</p>
<p>   - `trackOpenAICacheMetrics()` : Enregistre les m√©triques</p>
<p>   - `getOpenAICacheStats()` : R√©cup√®re les statistiques</p>
<p>   - Auto-cr√©ation des tables si n√©cessaire</p>

<p>4. **Dashboard Analytics**</p>
<p>   - Section d√©di√©e aux m√©triques OpenAI</p>
<p>   - Graphiques de performance</p>
<p>   - Indicateurs cl√©s en temps r√©el</p>

<h3>Flux de Donn√©es</h3>

<p>```</p>
<p>1. Requ√™te Chat ‚Üí ChatService</p>
<p>2. PromptUtils ‚Üí PromptCacheManager (prompt >1024 tokens)</p>
<p>3. chat_api.py ‚Üí OpenAI API (avec org ID)</p>
<p>4. R√©ponse ‚Üí openai_cache_utils (extraction m√©triques)</p>
<p>5. M√©triques ‚Üí CacheService.trackOpenAICacheMetrics()</p>
<p>6. Dashboard ‚Üí Affichage des statistiques</p>
<p>```</p>

<h2>üí° Best Practices</h2>

<h3>1. Structure des Prompts</h3>

<p>**‚úÖ Bon** : Placer le contenu statique en premier</p>
<p>```php</p>
<p>$prompt = PromptCacheManager::getCachablePrompt('chat_system');</p>
<p>$prompt .= "\n\n## Contexte Dynamique\n" . $userContext;</p>
<p>```</p>

<p>**‚ùå Mauvais** : M√©langer statique et dynamique</p>
<p>```php</p>
<p>$prompt = "User: " . $userInput . "\n" . $systemPrompt;</p>
<p>```</p>

<h3>2. Optimisation des Tokens</h3>

<p>- Les prompts doivent d√©passer 1024 tokens pour √™tre √©ligibles</p>
<p>- PromptCacheManager ajoute automatiquement du padding si n√©cessaire</p>
<p>- V√©rifiez r√©guli√®rement vos taux de cache dans le dashboard</p>

<h3>3. Monitoring et Ajustements</h3>

<p>1. **Surveillez le cache hit rate**</p>
<p>   - Objectif : >70% pour les conversations r√©p√©titives</p>
<p>   - Si <50%, v√©rifiez la structure de vos prompts</p>

<p>2. **Analysez les requ√™tes non √©ligibles**</p>
<p>   - Identifiez les prompts <1024 tokens</p>
<p>   - Consid√©rez l'ajout de contexte suppl√©mentaire</p>

<p>3. **Optimisez par mod√®le**</p>
<p>   - Utilisez la vue `openai_cache_model_stats`</p>
<p>   - Ajustez les mod√®les selon les performances</p>

<h2>üîß D√©pannage</h2>

<h3>Le cache hit rate est faible</h3>

<p>1. V√©rifiez que les prompts d√©passent 1024 tokens :</p>
<p>   ```php</p>
<p>   $tokenCount = PromptUtils::estimateTokenCount($prompt);</p>
<p>   echo "Tokens: $tokenCount";</p>
<p>   ```</p>

<p>2. Assurez-vous que l'Organization ID est configur√© :</p>
<p>   ```bash</p>
<p>   grep -r "org-HzNhomFpeY5ewhrUNlmpTehv" .</p>
<p>   ```</p>

<p>3. V√©rifiez les logs Python :</p>
<p>   ```bash</p>
<p>   tail -f python_api.log | grep "Cache"</p>
<p>   ```</p>

<h3>Les m√©triques ne s'affichent pas</h3>

<p>1. V√©rifiez que les tables existent :</p>
<p>   ```sql</p>
<p>   SELECT name FROM sqlite_master WHERE type='table' AND name LIKE 'openai%';</p>
<p>   ```</p>

<p>2. Ex√©cutez la migration si n√©cessaire :</p>
<p>   ```bash</p>
<p>   php migrate_openai_cache.php</p>
<p>   ```</p>

<p>3. V√©rifiez les logs d'erreur :</p>
<p>   ```bash</p>
<p>   tail -f php_errors.log | grep "openai"</p>
<p>   ```</p>

<h2>üìà Optimisations Futures</h2>

<p>1. **Analyse Pr√©dictive**</p>
<p>   - Identifier les patterns de conversation</p>
<p>   - Pr√©-charger les prompts fr√©quents</p>

<p>2. **Optimisation Dynamique**</p>
<p>   - Ajuster automatiquement la structure des prompts</p>
<p>   - A/B testing des formats de prompt</p>

<p>3. **Int√©gration Avanc√©e**</p>
<p>   - Webhooks pour alertes de performance</p>
<p>   - Export des m√©triques vers des outils d'analyse</p>

<h2>üìö Ressources</h2>

<p>- [Documentation OpenAI Prompt Caching](https://cookbook.openai.com/examples/prompt_caching101)</p>
<p>- [API Reference](https://platform.openai.com/docs/api-reference)</p>
<p>- [Pricing Calculator](https://openai.com/pricing)</p>

<h2>‚úÖ Checklist de D√©ploiement</h2>

<p>- [ ] Organization ID configur√© dans `.env`</p>
<p>- [ ] Migration de base de donn√©es ex√©cut√©e</p>
<p>- [ ] Tests de validation pass√©s</p>
<p>- [ ] Dashboard analytics accessible</p>
<p>- [ ] Monitoring des m√©triques actif</p>
<p>- [ ] Documentation lue par l'√©quipe</p>

<p>---</p>

<p>**Note** : Le prompt caching est automatique pour les prompts >1024 tokens avec les mod√®les support√©s (gpt-4o, gpt-4o-mini). Aucune modification de l'API n'est n√©cessaire, seule l'optimisation de la structure des prompts est requise.</p>
        </div>
    </div>
</body>
</html>
